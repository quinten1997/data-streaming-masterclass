# Data Streaming Training Repository

Welcome to the Data Streaming Training Repository! This repository contains exercises and materials to help you learn and practice data streaming concepts, with a focus on time-based joins and an introduction to Kafka. Below you will find an overview of each exercise folder and instructions on how to get started.

## Table of Contents

- [Exercise 1: Time-Based Joins](#exercise-1-time-based-joins)
- [Exercise 2: Introduction to Kafka](#exercise-2-introduction-to-kafka)

## Exercise 1: Time-Based Joins

### Overview

In this exercise, you will learn how to perform time-based joins using streaming data. Time-based joins are crucial for combining data streams based on temporal relationships, allowing you to correlate events that happen within specific time windows.

### Objectives

- Understand the concept of time-based joins in streaming data.
- Implement time-based joins using a streaming framework (e.g., Apache Kafka).

### Instructions

1. Navigate to the `time-based-joins` folder.
2. Review the `README.md` file inside the folder for detailed instructions on the exercise.
3. Follow the steps provided to set up your environment and run the example code.
4. Complete the exercises by implementing the required code and verifying the results.

### Prerequisites

- Basic understanding of streaming data concepts.
- Familiarity with SQL.

## Exercise 2: Introduction to Kafka

### Overview

This exercise introduces you to Apache Kafka, a distributed event streaming platform capable of handling high throughput and low latency data streams. You will learn how to set up Kafka, produce and consume messages, and understand Kafka's key components.

### Objectives

- Understand the architecture and components of Kafka.
- Set up a local Kafka environment.
- Produce and consume messages using Kafka.
- Explore Kafka topics, partitions, and consumer groups.

### Instructions

1. Navigate to the `introduction-to-kafka` folder.
2. Review the `README.md` file inside the folder for detailed instructions on the exercise.
3. Follow the steps provided to set up Kafka on your local machine.
4. Implement the producer and consumer code to send and receive messages through Kafka.
5. Complete the exercises to gain hands-on experience with Kafka.

### Prerequisites

- Basic understanding of event streaming concepts.
- Familiarity with Python or a similar programming language.

## Getting Started

To get started with these exercises, ensure you have the necessary prerequisites installed on your machine. Follow the instructions provided in each exercise folder to set up your environment and complete the exercises.

### General Requirements

- Python version 3.6 or above.
- Docker (for setting up Kafka environment).
- An IDE or text editor of your choice.

### Cloning the Repository

```sh
git clone https://github.com/quinten1997/datastreaming-training.git
cd datastreaming-training
